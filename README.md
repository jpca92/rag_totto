README ‚Äî Asistente GenAI con RAG, Embeddings, FAISS y Datos Estructurados
Descripci√≥n del Proyecto

Este proyecto implementa un Asistente GenAI corporativo que combina:

RAG (Retrieval Augmented Generation) para responder preguntas basadas en documentos internos (FAQ, pol√≠ticas, t√©rminos).

Modelos de Embedding (BERT MiniLM) para indexar texto.

FAISS como vector store para b√∫squedas sem√°nticas eficientes.

LLM (OpenAI GPT-5-nano) para generar respuestas naturales y contextuales.

Datos estructurados (CSV) para consultar informaci√≥n de inventario y atributos de productos mediante SKU.

El asistente detecta autom√°ticamente si la consulta del usuario contiene un SKU v√°lido y responde primero con informaci√≥n estructurada (stock, impermeabilidad) y luego integra este contexto con informaci√≥n de documentos usando RAG + LLM para producir una respuesta √∫nica, clara y profesional.

Caracter√≠sticas principales
1. Detecci√≥n autom√°tica de SKU

Cualquier palabra que comience por "SKU" se interpreta como un SKU v√°lido.

Permite consultas como:

"SKU100732 se puede devolver?"

"hay disponibilidad del sku100200?"

"el SKU100900 es impermeable?"

2. Respuestas h√≠bridas SKU + RAG

Si la consulta contiene un SKU, el asistente:

Obtiene stock desde inventory.csv.

Obtiene atributos del producto desde products.csv.

Recupera documentos relevantes mediante FAISS.

Genera una sola respuesta integrada con toda la informaci√≥n.

3. RAG completo para FAQs

Si la consulta no contiene SKU, se usa:

FAISS para recuperar chunks relevantes

BERT MiniLM para embeddings

GPT-4o-mini para responder con citas

4. Modo Debug opcional

En el panel lateral puedes activar un modo debug que muestra:

Chunks recuperados

Scores de FAISS

Prompt enviado al LLM

Ideal para demos, pruebas t√©cnicas y validaci√≥n del RAG.

5. Aceleraci√≥n por GPU (opcional)

Si hay una GPU disponible (torch.cuda.is_available()), el modelo de embeddings correr√° sobre CUDA autom√°ticamente.

üìÇ Estructura del Proyecto
project/
‚îÇ
‚îú‚îÄ app.py                         # Aplicaci√≥n Streamlit principal
‚îú‚îÄ README.md                      # Este archivo
‚îÇ
‚îú‚îÄ data/
‚îÇ   ‚îú‚îÄ products.csv               # Cat√°logo de productos
‚îÇ   ‚îú‚îÄ inventory.csv              # Inventario por SKU
‚îÇ   ‚îú‚îÄ faq.md                     # Preguntas frecuentes
‚îÇ   ‚îú‚îÄ politica_devoluciones.txt
‚îÇ   ‚îú‚îÄ politica_garantias.txt
‚îÇ   ‚îú‚îÄ terminos_servicio.txt
‚îÇ   ‚îî‚îÄ otros documentos .txt/.md
‚îÇ
‚îî‚îÄ requirements.txt                # Dependencias del proyecto

- Requisitos

Aseg√∫rate de tener instalado:

Python 3.12

pip

Entorno virtual es opcional pero recomendado.

- Instalaci√≥n
1. Crear entorno virtual
python -m venv venv

2. Activarlo

Windows:

venv\Scripts\activate


Linux/Mac:

source venv/bin/activate

3. Instalar dependencias
pip install -r requirements.txt

4. Configurar clave OpenAI
setx OPENAI_API_KEY "TU_API_KEY"


Cierra y abre la consola despu√©s de usar setx.

- Ejecutar la aplicaci√≥n

En la ra√≠z del proyecto:

streamlit run app.py


La interfaz estar√° disponible en:

http://localhost:8501

- Ejemplos de uso
Consulta con SKU
el SKU100732 se puede devolver?


Respuesta integrada:

Stock disponible

Impermeabilidad

Pol√≠tica de devoluciones (RAG)

Cita de fuente

Consulta sin SKU
¬øC√≥mo tramito una devoluci√≥n?


Respuesta:

Recuperada desde documentos FAQ

Generada por RAG + LLM

Modo Debug

Activa el interruptor en el sidebar para ver:

Fragmentos recuperados

Scores de similitud

Prompt completo enviado al LLM

- Tecnolog√≠as utilizadas
Componente	Tecnolog√≠a
Motor GenAI	OpenAI GPT-5-nano
Embeddings	Sentence-BERT MiniLM
Vector Store	FAISS FlatL2
UI	Streamlit
Procesamiento CSV	Pandas
Aceleraci√≥n	PyTorch GPU opcional

- Notas T√©cnicas

El sistema evita que RAG interfiera cuando la consulta requiere informaci√≥n estructurada, lo cual es una pr√°ctica est√°ndar en asistentes corporativos.

Los embeddings se cachean para optimizar tiempos de carga.

Los documentos se dividen en chunks para aumentar el recall del RAG.

La respuesta h√≠brida SKU + LLM est√° dise√±ada para integrarse de forma natural.

- Licencia

Este proyecto es de prop√≥sito demostrativo para pruebas t√©cnicas en GenAI/ML/Cloud.